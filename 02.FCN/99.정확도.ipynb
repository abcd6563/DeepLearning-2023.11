{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "seed = 2023\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1   2   3    4     5      6   7  8\n",
       "0   6  148  72  35    0  33.6  0.627  50  1\n",
       "1   1   85  66  29    0  26.6  0.351  31  0\n",
       "2   8  183  64   0    0  23.3  0.672  32  1\n",
       "3   1   89  66  23   94  28.1  0.167  21  0\n",
       "4   0  137  40  35  168  43.1  2.288  33  1\n",
       "5   5  116  74   0    0  25.6  0.201  30  0\n",
       "6   3   78  50  32   88  31.0  0.248  26  1\n",
       "7  10  115   0   0    0  35.3  0.134  29  0\n",
       "8   2  197  70  45  543  30.5  0.158  53  1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/pima-indians-diabetes.csv', skiprows=9,header=None)\n",
    "df.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: 8, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[8].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X data: scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaled = StandardScaler().fit_transform(df.iloc[:, :-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y data: label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "y_labeled = LabelEncoder().fit_transform(df[8].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_labeled, stratify=y_labeled, test_size=0.2, random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 80)                720       \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 12)                972       \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1705 (6.66 KB)\n",
      "Trainable params: 1705 (6.66 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential([\n",
    "    Dense(80, input_dim=8, activation='relu'),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6429 - accuracy: 0.7597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6429386138916016, 0.7597402334213257]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "hist1 = model1.fit(X_train, y_train, validation_split=0.2,\n",
    "                   epochs=200, batch_size=100, verbose=0)\n",
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl1, params1, acc1 = 2, 5865, 0.8810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_63 (Dense)            (None, 80)                720       \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 48)                3888      \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 20)                980       \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 8)                 168       \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5765 (22.52 KB)\n",
      "Trainable params: 5765 (22.52 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(80, input_dim=8, activation='relu'),\n",
    "    Dense(48, activation='relu'),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 2.5451 - accuracy: 0.6948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5450897216796875, 0.6948052048683167]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "hist2 = model2.fit(X_train, y_train, validation_split=0.2,\n",
    "                   epochs=200, batch_size=100, verbose=0)\n",
    "model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl2, params2, acc2 = 4, 9925, 0.8810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_68 (Dense)            (None, 80)                720       \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 64)                5184      \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 40)                2600      \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 24)                984       \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 10)                250       \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 4)                 44        \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9787 (38.23 KB)\n",
      "Trainable params: 9787 (38.23 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential([\n",
    "    Dense(80, input_dim=8, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(40, activation='relu'),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 2.9100 - accuracy: 0.7143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.909991502761841, 0.7142857313156128]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "hist3 = model3.fit(X_train, y_train, validation_split=0.2,\n",
    "                   epochs=200, batch_size=100, verbose=0)\n",
    "model3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl3, params3, acc3 = 6, 13947, 0.8095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_84 (Dense)            (None, 80)                720       \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 64)                5184      \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 48)                3120      \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 34)                1666      \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 24)                840       \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 16)                400       \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 10)                170       \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 4)                 44        \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12149 (47.46 KB)\n",
      "Trainable params: 12149 (47.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential([\n",
    "    Dense(80, input_dim=8, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(48, activation='relu'),\n",
    "    Dense(34, activation='relu'),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 3.1823 - accuracy: 0.6623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.1823489665985107, 0.6623376607894897]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "hist4 = model4.fit(X_train, y_train, validation_split=0.2,\n",
    "                   epochs=200, batch_size=100, verbose=0)\n",
    "model4.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl4, params4, acc4 = 8, 16309, 0.8571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>은닉층 갯수</th>\n",
       "      <th>파라메터 갯수</th>\n",
       "      <th>정확도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5865</td>\n",
       "      <td>0.8810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>9925</td>\n",
       "      <td>0.8810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>13947</td>\n",
       "      <td>0.8095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>16309</td>\n",
       "      <td>0.8571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   은닉층 갯수  파라메터 갯수     정확도\n",
       "0       2     5865  0.8810\n",
       "1       4     9925  0.8810\n",
       "2       6    13947  0.8095\n",
       "3       8    16309  0.8571"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = pd.DataFrame({\n",
    "    '은닉층 갯수': [hl1, hl2, hl3, hl4],\n",
    "    '파라메터 갯수': [params1, params2, params3, params4],\n",
    "    '정확도': [acc1, acc2, acc3, acc4]\n",
    "})\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_93 (Dense)            (None, 80)                720       \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 12)                972       \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1705 (6.66 KB)\n",
      "Trainable params: 1705 (6.66 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1b = Sequential([\n",
    "    Dense(80, input_dim=8, activation='relu'),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model1b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1b.compile('adam', 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model만 저장하는 callback 함수\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "mc1 = ModelCheckpoint('models/pima_best1.h5', monitor='val_loss', \n",
    "                      verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.68503, saving model to models\\pima_best1.h5\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 101: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 102: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 113: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 114: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 126: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 133: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 141: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 152: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 156: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 160: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 166: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 179: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 180: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 183: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 184: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 191: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.68503\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.68503\n"
     ]
    }
   ],
   "source": [
    "# epoch가 종료될 때 마다 callback 함수를 실행하도록 설정\n",
    "hist1 = model1b.fit(X_train, y_train, validation_split=0.2,\n",
    "                    epochs=200, batch_size=100, verbose=0,\n",
    "                    callbacks=[mc1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 0.7597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6018428802490234, 0.7597402334213257]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best model 불러와서 평가하기\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "best_model1 = load_model('models/pima_best1.h5')\n",
    "best_model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = [0.8810]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2b = Sequential([\n",
    "    Dense(80, input_dim=8, activation='relu'),\n",
    "    Dense(48, activation='relu'),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45303285121917725, 0.7792207598686218]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2b.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "mc2 = ModelCheckpoint('models/pima_best2.h5', monitor='val_loss', \n",
    "                      verbose=0, save_best_only=True)\n",
    "hist2 = model2b.fit(X_train, y_train, validation_split=0.2,\n",
    "                    epochs=100, batch_size=100, verbose=0,\n",
    "                    callbacks=[mc2])\n",
    "best_model2 = load_model('models/pima_best2.h5')\n",
    "best_model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score.append(0.8571)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3b = Sequential([\n",
    "    Dense(80, input_dim=8, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(40, activation='relu'),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46483314037323, 0.7857142686843872]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3b.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "mc3 = ModelCheckpoint('models/pima_best3.h5', monitor='val_loss', \n",
    "                      verbose=0, save_best_only=True)\n",
    "hist3 = model3b.fit(X_train, y_train, validation_split=0.2,\n",
    "                    epochs=100, batch_size=100, verbose=0,\n",
    "                    callbacks=[mc3])\n",
    "best_model3 = load_model('models/pima_best3.h5')\n",
    "best_model3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score.append(0.8095)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4b = Sequential([\n",
    "    Dense(80, input_dim=8, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(48, activation='relu'),\n",
    "    Dense(34, activation='relu'),\n",
    "    Dense(24, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46944674849510193, 0.7792207598686218]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4b.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "mc4 = ModelCheckpoint('models/pima_best4.h5', monitor='val_loss', \n",
    "                      verbose=0, save_best_only=True)\n",
    "hist4 = model4b.fit(X_train, y_train, validation_split=0.2,\n",
    "                    epochs=100, batch_size=100, verbose=0,\n",
    "                    callbacks=[mc4])\n",
    "best_model4 = load_model('models/pima_best4.h5')\n",
    "best_model4.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score.append(0.7857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>은닉층 갯수</th>\n",
       "      <th>파라메터 갯수</th>\n",
       "      <th>정확도</th>\n",
       "      <th>best model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5865</td>\n",
       "      <td>0.8810</td>\n",
       "      <td>0.8810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>9925</td>\n",
       "      <td>0.8810</td>\n",
       "      <td>0.8571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>13947</td>\n",
       "      <td>0.8095</td>\n",
       "      <td>0.8095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>16309</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.7857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   은닉층 갯수  파라메터 갯수     정확도  best model\n",
       "0       2     5865  0.8810      0.8810\n",
       "1       4     9925  0.8810      0.8571\n",
       "2       6    13947  0.8095      0.8095\n",
       "3       8    16309  0.8571      0.7857"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf['best model'] = best_score\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
